clear
clc
l
L
x <- 0.8836+0.0564+0.0009+0.0376
x - 0.0376
x
0.0375-0.0215
d <- 0.0215+0.0012+0.00188+0.004+0.006+0.004+0.001
0.0215*4+0.0012*6+0.00188*9+0.0004*10+0.0006*11+0.0004*15+0.0001*20
0.12872/d
0.12872/0.05
runTime <- c(0.001418138, 4.95523E-4, 0.001440276, 0.005974989, 0.009176647, 0.010530942, 0.047961293, 0.198864462, 0.875263574, 3.968954248, 16.478082562, 68.734433724, 279.915478711)
plot(runTime)
dimension <- c(2,4,8,16,32,64,128,256,512,1024,2048,4096,8192)
plot(dimension, runTime)
plot(dimension, runTime, 'lines')
plot(dimension, runTime, 'lines', main="Minimal Flexible Distance Algorithm 1000 replications",
xlab="Dimension [N]", ylab="run-time [millisecond]")
plot(dimension, runTime, 'lines', main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
runTime <- c(0.001418138, 4.95523E-4, 0.001440276, 0.005974989, 0.009176647, 0.010530942, 0.047961293, 0.198864462, 0.875263574, 3.968954248, 16.478082562, 68.734433724, 279.915478711, 1070.830521243)
dimension <- c(2,4,8,16,32,64,128,256,512,1024,2048,4096,8192, 16384)
plot(dimension, runTime, 'lines', main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
plot(dimension, runTime, 'lines',col="26",
main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
plot(dimension, runTime, 'lines', col="b",
main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
plot(dimension, runTime, 'lines', col="bl",
main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
plot(dimension, runTime, type="lines", col="bl",
main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
plot(dimension, runTime, type='lines', col='bl',
main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
plot(dimension, runTime, type='lines',,
plot(dimension, runTime, type='lines',
main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
plot(dimension, runTime,'lines',
main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
plot(dimension, runTime,'lines',main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
plot(dimension, runTime,'lines', colors="blue", main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
plot(dimension, runTime,'lines', col="blue", main="Minimal Flexible Distance Algorithm: 1000 replications",
xlab="Dimension", ylab="run-time [millisecond]")
install.packages("quantmod")
library(selectiongain)
set.seed(42)  # 42:The answer to life, the universe and everything.
alpha=0.95
corr=diag(2)
calculatefromalpha(alpha, dim=2, corr=corr)
######
install.packages("selectiongain")
install.packages("selectiongain")
library(selectiongain)
alpha=0.95
corr=diag(2)
calculatefromalpha(alpha, dim=2, corr=corr)
qt(0.99, df=7)
qt(0.01, df=7)
?rmgarch
#################################################################################################################
rm(list=ls())  # remove all variables in R
library(tseries)
library(rugarch)
library(rmgarch)
library(parallel)
library(zoo)
library(fGarch)
setwd("~/Documents/Python/PycharmProjects/ml_tue2017/source/main/resources/Data/multivariate_analysis")
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
####################################################################################################
######                               Tranquil Market Conditions                              #######
####################################################################################################
# Data sample import
data <- read.csv("DJI30_returns_1987_2001.csv", row.names=1, header=T)[1:2224,] # Data sample: 17/3/1987-29/12/1995 intial in sample period: 1720 observations
data$Date <- NULL
T <- 504  # Out-of-sample test sample: 3/1/1994-29/12/1995
N <- 30  # number of assets under consideration
w <- c(rep(1/N, N))  # asset weight vector (assume equal weights)
# Same first stage conditional mean filtration (unconditional mean)
a_t <- data - rep(colMeans(data), rep.int(nrow(data), ncol(data)))  # r_t - mu_t = a_t = epsilon_t
t <- c((nrow(data)-T):(nrow(data)-1))
vol_data_tranquil_gjr_sstd <- read.csv(file="volatilities_gjr_sstd_DJI30_1994_1995.csv", row.names=1)
## Load conditional correlations and volatilities data
vol_data_tranquil_garch<- read.csv(file="volatilities_garch_norm_DJI30_1994_1995.csv", row.names=1)
cor_KNN100_pearson_tranquil <- read.csv(file="pearson/pearson_cor_estimates/cor_knn100_pearson_10_DJI30_1994_1995.csv", row.names=1)
filenames = 'KNN100_pearson'
for (filename in filenames) {
cor_data <- eval(parse(text=paste("cor_", filename, "_tranquil", sep="")))
cvar_mat_99[paste(filename,"_garch", sep=""), ] <- portfolio_VaR(vol_data_tranquil_garch, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/tranquil/var_",filename,"_garch_1994_1995.csv", sep=""), T, w)$cvar
cvar_mat_99[paste(filename,"_gjr", sep=""), ] <- portfolio_VaR(vol_data_tranquil_gjr_sstd, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/tranquil/var_",filename,"_gjr_1994_1995.csv", sep=""), T, w)$cvar
}
#####    Value-at-Risk Estimation   #####
alpha <- c(0.99, 0.975, 0.95, 0.9, 0.8, 0.6, 0.4, 0.2, 0.1, 0.05, 0.025, 0.01)
mu_portfolio_loss <- w%*%colMeans(data)  # Expected portfolio return (assumed constant through sample mean)
## Compute true Value-at-Risk
VaR_true <- as.matrix(tail(data, T))%*%w  #  Out-of-sample realized returns for a long position in an equally weighted portfolio
filenames = 'KNN100_pearson'
for (filename in filenames) {
cor_data <- eval(parse(text=paste("cor_", filename, "_tranquil", sep="")))
cvar_mat_99[paste(filename,"_garch", sep=""), ] <- portfolio_VaR(vol_data_tranquil_garch, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/tranquil/var_",filename,"_garch_1994_1995.csv", sep=""), T, w)$cvar
cvar_mat_99[paste(filename,"_gjr", sep=""), ] <- portfolio_VaR(vol_data_tranquil_gjr_sstd, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/tranquil/var_",filename,"_gjr_1994_1995.csv", sep=""), T, w)$cvar
}
for (filename in filenames) {
cor_data <- eval(parse(text=paste("cor_", filename, "_tranquil", sep="")))
#cvar_mat_99[paste(filename,"_garch", sep=""), ] <- portfolio_VaR(vol_data_tranquil_garch, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/tranquil/var_",filename,"_garch_1994_1995.csv", sep=""), T, w)$cvar
cvar_mat_99[paste(filename,"_gjr", sep=""), ] <- portfolio_VaR(vol_data_tranquil_gjr_sstd, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/tranquil/var_",filename,"_gjr_1994_1995.csv", sep=""), T, w)$cvar
}
var_files <- c('var_knn100_pearson_garch_1994_1995.csv', 'var_knn100_pearson_gjr_1994_1995.csv')
for (var_file in var_files) {
VaR_est = read.table(paste("VaR/tranquil/", var_file, sep=""), sep=",", skip=1)
VaR_est[1] = NULL
colnames(VaR_est) <- 1-alpha
result <- uc_ind_test(VaR_est=VaR_est, cl=alpha, file=paste("backtest/tranquil/backtest_", var_file, sep=""))
}
# Non-rejection regions tranwuil market conditions
for (a in alpha){
print(sprintf("CI %f: [%i,%i]",a, regions_uc_test(T=T, alpha=a)$lb, regions_uc_test(T=T, alpha=a)$ub))
}
#################################################################################################################
rm(list=ls())  # remove all variables in R
library(tseries)
library(rugarch)
library(rmgarch)
library(parallel)
library(zoo)
library(fGarch)
setwd("~/Documents/Python/PycharmProjects/ml_tue2017/source/main/resources/Data/multivariate_analysis")
source("R/fun_VaR_backtesting.R")
set.seed(42)  # 42:The answer to life, the universe and everything.
## Load conditional correlations and volatilities data
vol_data_volatile_garch<- read.csv(file="volatilities_garch_norm_DJI30_2000_2001.csv", row.names=1)
vol_data_volatile_gjr_sstd <- read.csv(file="volatilities_gjr_sstd_DJI30_2000_2001.csv", row.names=1)
cor_KNN100_kendall_volatile <- read.csv(file="kendall/kendall_cor_estimates/cor_knn100_kendall_10_DJI30_2000_2001.csv", row.names=1)
#####    Value-at-Risk Estimation   #####
alpha <- c(0.99, 0.975, 0.95, 0.9, 0.8, 0.6, 0.4, 0.2, 0.1, 0.05, 0.025, 0.01)
mu_portfolio_loss <- w%*%colMeans(data)  # Expected portfolio return (assumed constant through sample mean)
#####    Value-at-Risk Estimation   #####
alpha <- c(0.99, 0.975, 0.95, 0.9, 0.8, 0.6, 0.4, 0.2, 0.1, 0.05, 0.025, 0.01)
mu_portfolio_loss <- w%*%colMeans(data)  # Expected portfolio return (assumed constant through sample mean)
####################################################################################################
######                               Volatile Market Conditions                              #######
####################################################################################################
data <- read.csv("DJI30_returns_1987_2001.csv", row.names=1, header=T) # Data sample: 17/3/1987-31/12/2001
data$Date <- NULL
T <- 500  # Out-of-sample test sample: 3/1/2000-31/12/2001
N <- 30  # number of assets under consideration
w <- c(rep(1/N, N))  # asset weight vector (assume equal weights)
a_t <- data - rep(colMeans(data), rep.int(nrow(data), ncol(data)))  # r_t - mu_t = a_t = epsilon_t
t <- c((nrow(data)-T):(nrow(data)-1))
## Load conditional correlations and volatilities data
vol_data_volatile_garch<- read.csv(file="volatilities_garch_norm_DJI30_2000_2001.csv", row.names=1)
vol_data_volatile_gjr_sstd <- read.csv(file="volatilities_gjr_sstd_DJI30_2000_2001.csv", row.names=1)
cor_KNN100_kendall_volatile <- read.csv(file="kendall/kendall_cor_estimates/cor_knn100_kendall_10_DJI30_2000_2001.csv", row.names=1)
#####    Value-at-Risk Estimation   #####
alpha <- c(0.99, 0.975, 0.95, 0.9, 0.8, 0.6, 0.4, 0.2, 0.1, 0.05, 0.025, 0.01)
mu_portfolio_loss <- w%*%colMeans(data)  # Expected portfolio return (assumed constant through sample mean)
## Compute true Value-at-Risk
VaR_true <- as.matrix(tail(data, T))%*%w  #  Out-of-sample realized returns for a long position in an equally weighted portfolio
filenames = 'KNN100-Kendall'
for (filename in filenames) {
cor_data <- eval(parse(text=paste("cor_", filename, "_volatile", sep="")))
cvar_mat_99[paste(filename,"_garch", sep=""), ] <- portfolio_VaR(vol_data_volatile_garch, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/volatile/var_",filename,"_garch_2000_2001.csv", sep=""), T, w)$cvar
cvar_mat_99[paste(filename,"_gjr", sep=""), ] <- portfolio_VaR(vol_data_volatile_gjr_sstd, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/volatile/var_",filename,"_gjr_2000_2001.csv", sep=""), T, w)$cvar
}
filenames = 'KNN100-Kendall'
cor_KNN100_kendall_volatile <- read.csv(file="kendall/kendall_cor_estimates/cor_knn100_kendall_10_DJI30_2000_2001.csv", row.names=1)
filenames = 'KNN100-Kendall'
for (filename in filenames) {
cor_data <- eval(parse(text=paste("cor_", filename, "_volatile", sep="")))
cvar_mat_99[paste(filename,"_garch", sep=""), ] <- portfolio_VaR(vol_data_volatile_garch, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/volatile/var_",filename,"_garch_2000_2001.csv", sep=""), T, w)$cvar
cvar_mat_99[paste(filename,"_gjr", sep=""), ] <- portfolio_VaR(vol_data_volatile_gjr_sstd, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/volatile/var_",filename,"_gjr_2000_2001.csv", sep=""), T, w)$cvar
}
filenames = 'KNN100_kendall'
for (filename in filenames) {
cor_data <- eval(parse(text=paste("cor_", filename, "_volatile", sep="")))
cvar_mat_99[paste(filename,"_garch", sep=""), ] <- portfolio_VaR(vol_data_volatile_garch, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/volatile/var_",filename,"_garch_2000_2001.csv", sep=""), T, w)$cvar
cvar_mat_99[paste(filename,"_gjr", sep=""), ] <- portfolio_VaR(vol_data_volatile_gjr_sstd, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/volatile/var_",filename,"_gjr_2000_2001.csv", sep=""), T, w)$cvar
}
for (filename in filenames) {
cor_data <- eval(parse(text=paste("cor_", filename, "_volatile", sep="")))
#cvar_mat_99[paste(filename,"_garch", sep=""), ] <- portfolio_VaR(vol_data_volatile_garch, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/volatile/var_",filename,"_garch_2000_2001.csv", sep=""), T, w)$cvar
cvar_mat_99[paste(filename,"_gjr", sep=""), ] <- portfolio_VaR(vol_data_volatile_gjr_sstd, cor_data, mu_portfolio_loss, alpha, file=paste("VaR/volatile/var_",filename,"_gjr_2000_2001.csv", sep=""), T, w)$cvar
}
var_files <- c('var_KNN100_kendall_garch_2000_2001.csv', 'var_KNN100_kendall_gjr_2000_2001.csv')
for (var_file in var_files) {
VaR_est = read.table(paste("VaR/volatile/", var_file, sep=""), sep=",", skip=1)
VaR_est[1] = NULL
colnames(VaR_est) <- 1-alpha
result <- uc_ind_test(VaR_est=VaR_est, cl=alpha, file=paste("backtest/volatile/backtest_", var_file, sep=""))
}
